Task1: Kafka Cluster Setup
==========================


cd Downloads
ls

ssh -i Broker-1_key.pem azureuser@20.193.143.241
yes

cd Downloads
ls

ssh -i Broker-2_key.pem azureuser@20.40.44.235
yes

cd Downloads
ls

ssh -i Broker-3_key.pem azureuser@4.240.100.177
yes



============================================================
sudo su
cd /opt





----------------------------------------------------------------------------------------
To download

curl -O https://packages.confluent.io/archive/7.6/confluent-community-7.6.4.tar.gz

tar xzf confluent-community-7.6.4.tar.gz

Install Java

sudo apt update
sudo apt install openjdk-11-jre

=============================================

10.0.0.4
10.0.0.5
10.0.0.6

server.1=10.0.0.4/
#server.2=10.0.0.5/
#server.3=10.0.0.6/

server.1=10.0.0.4:2181
-----------------------------------------------------------

dataDir=/opt/data/zookeeper
clientPort=2181
maxClientCnxns=60
admin.enableServer=false
tickTime=3000
initLimit=10
syncLimit=2
server.1=0.0.0.0:2888:3888
#server.2=172.31.85.5:2888:3888
#server.3=172.31.87.15:2888:3888

--------------------------------------------------


root@Broker-1:/opt/kafka/etc/kafka/data/zookeeper# vi /etc/systemd/system/zookeeper.service

------------------------------------------------------------------------------------------------

[Unit]
Requires=network.target remote-fs.target
After=network.target remote-fs.target

[Service]
Type=simple
User=root
ExecStart=/opt/kafka/bin/zookeeper-server-start /opt/kafka/etc/kafka/zookeeper.properties
ExecStop=/opt/kafka/bin/zookeeper-server-stop
Restart=on-abnormal

[Install]
WantedBy=multi-user.target

---------------------------------------------------------------------------------------------------

root@Broker-1:/opt/kafka/etc/kafka/data/zookeeper# systemctl daemon-reload

systemctl status zookeeper
systemctl start zookeeper

============================================================================================

echo srvr | nc localhost 2181
---------------------------------------------------------------------------------
vi /opt/kafka/etc/kafka/server.properties

broker.id=1
#listeners=PLAINTEXT://:9092
advertised.listeners=PLAINTEXT://10.0.0.4:9092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/opt/data/kafka
num.partitions=3
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=3
log.flush.interval.messages=10000
log.flush.interval.ms=1000
log.retention.hours=168
#log.retention.bytes=1073741824
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connect=10.0.0.4:2181
zookeeper.connection.timeout.ms=18000
#metric.reporters=io.confluent.metrics.reporter.ConfluentMetricsReporter
#confluent.metrics.reporter.bootstrap.servers=localhost:9092
#confluent.metrics.reporter.topic.replicas=1
group.initial.rebalance.delay.ms=0

================================================================
broker.id=2
#listeners=PLAINTEXT://:9092
advertised.listeners=PLAINTEXT://10.0.0.5:9092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/opt/data/kafka
num.partitions=3
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=3
log.flush.interval.messages=10000
log.flush.interval.ms=1000
log.retention.hours=168
#log.retention.bytes=1073741824
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
zookeeper.connect=10.0.0.4:2181
zookeeper.connection.timeout.ms=18000
#metric.reporters=io.confluent.metrics.reporter.ConfluentMetricsReporter
#confluent.metrics.reporter.bootstrap.servers=localhost:9092
#confluent.metrics.reporter.topic.replicas=1
group.initial.rebalance.delay.ms=0



--------------------------------------------------------------------
vi /etc/systemd/system/kafka.service

[Unit]
Requires=network.target remote-fs.target
After=network.target remote-fs.target

[Service]
Type=simple
User=root
ExecStart=/opt/kafka/bin/kafka-server-start /opt/kafka/etc/kafka/server.properties
ExecStop=/opt/kafka/bin/kafka-server-stop
Restart=on-abnormal

[Install]
WantedBy=multi-user.target
---------------------------------------------------------------------

systemctl daemon-reload

systemctl status kafka
systemctl start kafka

=========================================================================================

Task2: Kafka Topic Configuration and Data Flow


Topic creation

/opt/kafka/bin/kafka-topics --bootstrap-server localhost:9092 -create -topic A -partitions 6 -replication-factor 3

/opt/kafka/bin/kafka-topics --bootstrap-server localhost:9092 -create -topic B -partitions 2 -replication-factor 1


list the topic
 /opt/kafka/bin/kafka-topics --bootstrap-server localhost:9092 -list


Describe Topic
/opt/kafka/bin/kafka-topics --bootstrap-server localhost:9092 -describe -topic B 

----------------------------------------------------------------------------------------

Producer 
/opt/kafka/bin/kafka-console-producer --bootstrap-server localhost:9092 -topic A

Consumer
/opt/kafka/bin/kafka-console-consumer --bootstrap-server localhost:9092 -topic A -from-beginning

=====================================================================================================




========================================================================================================================================

vi /etc/confluent-control-center/control-center-production.properties

bootstrap.servers=<10.0.0.4:9092,10.0.0.5:9092,10.0.0.6:9092>
confluent.controlcenter.data.dir=/var/lib/confluent/control-center
zookeeper.connect=<10.0.0.4:2181>

---------------------------------------------------------------------------------------

# host/port pairs to use for establishing the initial connection to the Kafka cluster
bootstrap.servers=<10.0.0.4:9092,10.0.0.5:9092,10.0.0.6:9092>

# location for Control Center data
confluent.controlcenter.data.dir=/var/lib/confluent/control-center

# ZooKeeper connection string with host and port of a ZooKeeper servers
zookeeper.connect=<10.0.0.4:2181>

=====================================================================================================================================


